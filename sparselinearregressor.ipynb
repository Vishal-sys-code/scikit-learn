{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Implementing the SparseLinearRegressor\n\n* **Issue number**:30139 \n* **Title of the Issue**: The `input_tags.sparse` flag is often incorrect","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom scipy import sparse as sp\nfrom sklearn.base import RegressorMixin, MultiOutputMixin\nfrom sklearn.linear_model._base import LinearModel\nfrom sklearn.utils.validation import check_X_y\nfrom scipy.sparse.linalg import lsqr\nfrom scipy import optimize\nfrom sklearn.preprocessing import StandardScaler\nfrom joblib import Parallel, delayed\n\nclass SparseLinearRegressor(MultiOutputMixin, RegressorMixin, LinearModel):\n    \"\"\"\n    Custom implementation of a linear regression model that supports\n    fitting on sparse data and can enforce non-negativity constraints.\n\n    Parameters\n    ----------\n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model. If set to False,\n        no intercept will be used in calculations (i.e., data is expected to be centered).\n        \n    copy_X : bool, default=True\n        If True, a copy of X will be made; else, it may overwrite X.\n        \n    n_jobs : int or None, default=None\n        The number of jobs to use for the computation. None means 1 unless\n        in a joblib.parallel_backend context.\n        \n    positive : bool, default=False\n        If True, the coefficients are constrained to be positive.\n    \"\"\"\n    \n    def __init__(self, *, fit_intercept=True, copy_X=True, n_jobs=None, positive=False):\n        self.fit_intercept = fit_intercept\n        self.copy_X = copy_X\n        self.n_jobs = n_jobs\n        self.positive = positive\n\n    def _get_tags(self):\n        \"\"\"\n        Retrieve the tags associated with the estimator.\n\n        Returns\n        -------\n        dict\n            Tags related to the model's behavior.\n        \"\"\"\n        tags = super()._get_tags()\n        tags['sparse'] = not self.positive  # Adjust tag based on positivity constraint\n        return tags\n\n    def fit(self, X, y, sample_weight=None):\n        \"\"\"\n        Fit the model to the provided data.\n\n        Parameters\n        ----------\n        X : array-like or sparse matrix of shape (n_samples, n_features)\n            Training data.\n\n        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n            Target values.\n\n        sample_weight : array-like of shape (n_samples,), default=None\n            Individual weights for each sample.\n\n        Returns\n        -------\n        self : object\n            Fitted estimator.\n        \"\"\"\n        n_jobs_ = self.n_jobs\n        accept_sparse = False if self.positive else [\"csr\", \"csc\", \"coo\"]\n\n        # Validating input data\n        X, y = check_X_y(X, y, accept_sparse=accept_sparse, multi_output=True, y_numeric=True)\n\n        # Preprocess data (center and scale)\n        X, y, X_offset, y_offset, X_scale = _preprocess_data(X, y, fit_intercept=self.fit_intercept, copy=self.copy_X)\n\n        if self.positive:\n            # Use non-negative least squares for fitting\n            if y.ndim < 2:\n                self.coef_ = optimize.nnls(X, y)[0]\n            else:\n                outs = Parallel(n_jobs=n_jobs_)(delayed(optimize.nnls)(X, y[:, j]) for j in range(y.shape[1]))\n                self.coef_ = np.vstack([out[0] for out in outs])\n        elif sp.issparse(X):\n            # For sparse inputs, solve using lsqr\n            X_offset_scale = X_offset / X_scale\n            X_centered = sp.linalg.LinearOperator(\n                shape=X.shape,\n                matvec=lambda b: X.dot(b) - b.dot(X_offset_scale),\n                rmatvec=lambda b: X.T.dot(b) - X_offset_scale * b.sum()\n            )\n            if y.ndim < 2:\n                self.coef_ = lsqr(X_centered, y)[0]\n            else:\n                outs = Parallel(n_jobs=n_jobs_)(delayed(lsqr)(X_centered, y[:, j].ravel()) for j in range(y.shape[1]))\n                self.coef_ = np.vstack([out[0] for out in outs])\n        else:\n            # For dense inputs, use least squares\n            self.coef_, _, self.rank_, self.singular_ = np.linalg.lstsq(X, y, rcond=None)\n            self.coef_ = self.coef_.T\n\n        # Ensuring coefficients are 1D if y is 1D\n        if y.ndim == 1:\n            self.coef_ = np.ravel(self.coef_)\n\n        # Set intercept based on preprocessing\n        self._set_intercept(X_offset, y_offset, X_scale)\n        return self\n\n# Utility functions needed for fitting\ndef _preprocess_data(X, y, fit_intercept=True, copy=True, sample_weight=None):\n    \"\"\"\n    Preprocess the data by centering it and scaling if necessary.\n\n    Parameters\n    ----------\n    X : array-like or sparse matrix of shape (n_samples, n_features)\n        Training data.\n    \n    y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n        Target values.\n    \n    fit_intercept : bool, default=True\n        Whether to calculate the intercept for this model.\n\n    copy : bool, default=True\n        If True, a copy of X will be made; else, it may overwrite X.\n\n    sample_weight : array-like of shape (n_samples,), default=None\n        Individual weights for each sample.\n\n    Returns\n    -------\n    tuple\n        Processed X, y, and offset/scale values.\n    \"\"\"\n    if fit_intercept:\n        # Centering data\n        if sp.issparse(X):\n            X_offset = np.average(X.toarray(), axis=0, weights=sample_weight)\n        else:\n            X_offset = np.average(X, axis=0, weights=sample_weight)\n        X = X - X_offset\n\n        y_offset = np.average(y, axis=0, weights=sample_weight)\n        y = y - y_offset\n    else:\n        X_offset = np.zeros(X.shape[1], dtype=X.dtype)\n        y_offset = 0. if y.ndim == 1 else np.zeros(y.shape[1], dtype=y.dtype)\n\n    # Optionally scale data\n    if fit_intercept:\n        X_scale = np.ones(X.shape[1], dtype=X.dtype)\n    else:\n        X_scale = StandardScaler(with_mean=False).fit(X).scale_\n\n    return X, y, X_offset, y_offset, X_scale\n\n# Test Code\nif __name__ == \"__main__\":\n    # Sample sparse input data\n    X_sparse = sp.csr_matrix([[1, 2], [3, 4], [5, 6]])\n    y = np.array([1, 2, 3])\n\n    # Testing with positive=False (should accept sparse)\n    reg = SparseLinearRegressor(positive=False)\n    tags = reg._get_tags()\n    print(\"Sparse support with positive=False:\", tags['sparse'])\n\n    # Checking actual behavior with sparse input (positive=False)\n    try:\n        reg.fit(X_sparse, y)\n        print(\"Fitting with sparse data (positive=False) succeeded.\")\n    except ValueError as e:\n        print(\"Error during fit with sparse data (positive=False):\", e)\n\n    # Checking actual behavior with sparse input (positive=True)\n    try:\n        reg = SparseLinearRegressor(positive=True)\n        reg.fit(X_sparse.toarray(), y)  # Convert sparse to dense\n        print(\"Fitting with sparse data (positive=True) succeeded after conversion to dense.\")\n    except ValueError as e:\n        print(\"Error during fit with sparse data (positive=True):\", e)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T21:00:13.988939Z","iopub.execute_input":"2024-10-24T21:00:13.989417Z","iopub.status.idle":"2024-10-24T21:00:14.026184Z","shell.execute_reply.started":"2024-10-24T21:00:13.989344Z","shell.execute_reply":"2024-10-24T21:00:14.024778Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Sparse support with positive=False: True\nFitting with sparse data (positive=False) succeeded.\nFitting with sparse data (positive=True) succeeded after conversion to dense.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Testing with some datas","metadata":{}},{"cell_type":"code","source":"X_new = sp.csr_matrix([[2, 3], [4, 5]])\n\n# For positive=True, convert to dense\nreg_positive = SparseLinearRegressor(positive=True)\nreg_positive.fit(X_sparse.toarray(), y)\npredictions_positive = reg_positive.predict(X_new.toarray())  # Convert to dense\nprint(\"Predictions with positive=True:\", predictions_positive)\n\n# For positive=False, use sparse directly\nreg_negative = SparseLinearRegressor(positive=False)\nreg_negative.fit(X_sparse, y)\npredictions_negative = reg_negative.predict(X_new)\nprint(\"Predictions with positive=False:\", predictions_negative)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T21:00:14.028191Z","iopub.execute_input":"2024-10-24T21:00:14.028576Z","iopub.status.idle":"2024-10-24T21:00:14.050411Z","shell.execute_reply.started":"2024-10-24T21:00:14.028536Z","shell.execute_reply":"2024-10-24T21:00:14.048918Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"Predictions with positive=True: [1.5 2.5]\nPredictions with positive=False: [1.5 2.5]\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom scipy import sparse as sp\n\n# Creating a larger sparse dataset\n# For demonstration, let's create a sparse matrix of shape (1000, 50)\n# where only 5% of the entries are non-zero.\nn_samples = 1000\nn_features = 50\ndensity = 0.05  # 5% non-zero entries\n\n# Generating a random sparse matrix\nX_large_sparse = sp.rand(n_samples, n_features, density=density, format='csr')\ny_large = np.random.rand(n_samples)  # Random target values\n\n# New input data for predictions (also sparse)\nX_new = sp.csr_matrix([[2, 0, 3] + [0] * (n_features - 3), \n                        [4, 0, 0] + [0] * (n_features - 3)])\n\n# For positive=True, convert to dense\nreg_positive = SparseLinearRegressor(positive=True)\n\n# Fit the model with sparse input converted to dense\nreg_positive.fit(X_large_sparse.toarray(), y_large)\npredictions_positive = reg_positive.predict(X_new.toarray())  # Convert to dense for prediction\nprint(\"Predictions with positive=True:\", predictions_positive)\n\n# For positive=False, fit the model with sparse data directly\nreg_negative = SparseLinearRegressor(positive=False)\nreg_negative.fit(X_large_sparse, y_large)\n\n# Using the sparse new input directly for prediction\npredictions_negative = reg_negative.predict(X_new)\nprint(\"Predictions with positive=False:\", predictions_negative)","metadata":{"execution":{"iopub.status.busy":"2024-10-24T21:00:14.052027Z","iopub.execute_input":"2024-10-24T21:00:14.052505Z","iopub.status.idle":"2024-10-24T21:00:14.090014Z","shell.execute_reply.started":"2024-10-24T21:00:14.052448Z","shell.execute_reply":"2024-10-24T21:00:14.088812Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Predictions with positive=True: [0.93789956 0.71773219]\nPredictions with positive=False: [0.97155177 0.7485261 ]\n","output_type":"stream"}]}]}